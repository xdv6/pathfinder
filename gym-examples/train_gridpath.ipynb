{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import gym_game\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pkg_resources\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# pkg_resources.get_distribution(\"gym\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "config =  {\n",
    "    \"BATCH_SIZE\":32,\n",
    "    \"GAMMA\" : 0.95,\n",
    "    \"EPS_START\": 1,\n",
    "    \"EPS_END\" : 0.05,\n",
    "    \"EPS_DECAY\" : 200,\n",
    "    \"lr\":0.001, \n",
    "    \"weight_decay\":1e-5,\n",
    "    # lengte van pad *4\n",
    "    \"REPLAY_BUFFER\":600,\n",
    "    \"EPISODES\": 400,\n",
    "    \"TARGET_UPDATE\": 10,\n",
    "    \"SAVE_FREQ\": 10,\n",
    "    \"RESET_ENV_FREQ\": 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"difference_in_distance_reward\", entity=\"xdvisch\", config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xande\\AppData\\Local\\Temp\\ipykernel_4796\\4108622542.py:8: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  T.Resize(40, interpolation=Image.CUBIC),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(\"GridWorld-v0\", render_mode=\"rgb_array\").unwrapped\n",
    "\n",
    "\n",
    "\n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps\n",
    "```text\n",
    "    - 0: RIGHT\n",
    "    - 1: DOWN\n",
    "    - 2: LEFT\n",
    "    - 3: UP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render().transpose((2, 0, 1))  # transpose into torch order (CHW)\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    \n",
    "    # coordinaat van linkerbovenhoek rechthoek\n",
    "    x_pixel_coo_agent = env._agent_location[0] * env.pix_square_size\n",
    "    y_pixel_coo_agent = env._agent_location[1] * env.pix_square_size\n",
    "\n",
    "    x_coo_right_up = x_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    x_coo_right_down = x_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    y_coo_left_down = y_pixel_coo_agent + 2 * env.pix_square_size\n",
    "    y_coo_left_up = y_pixel_coo_agent - env.pix_square_size\n",
    "\n",
    "    # left handed coordinate system\n",
    "    screen = screen[:,y_coo_left_up:y_coo_left_down, x_coo_right_down:x_coo_right_up]\n",
    "\n",
    "    # Convert to float, rescare, convert to torch tensor (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "example_screen = get_screen()\n",
    "# print(f\"shape of screen: {screen.example_screen}\")\n",
    "plt.imshow(example_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "\n",
    "\n",
    "    # eps_threshold = config.get(\"EPS_END\") + (config.get(\"EPS_START\") - config.get(\"EPS_END\")) * math.exp(-1. * steps_done / config.get(\"EPS_DECAY\"))\n",
    "    eps_threshold = config.get(\"EPS_END\")\n",
    "\n",
    "    wandb.log({\"eps_threshold\": eps_threshold})\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_model(policy_net, optimizer, memory):\n",
    "    if len(memory) < config.get(\"BATCH_SIZE\"):\n",
    "        return\n",
    "    transitions = memory.sample( config.get(\"BATCH_SIZE\"))\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros( config.get(\"BATCH_SIZE\"), device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = ((next_state_values * config.get(\"GAMMA\") + reward_batch).unsqueeze(1))\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.human_rendering import HumanRendering\n",
    "\n",
    "\n",
    "# Define the custom x axis metric\n",
    "wandb.define_metric(\"episode\")\n",
    "\n",
    "# Define which metrics to plot against that x-axis\n",
    "wandb.define_metric(\"reached_target\", step_metric='episode')\n",
    "wandb.define_metric(\"win_count\", step_metric='episode')\n",
    "wandb.define_metric(\"mean_reward\", step_metric='episode')\n",
    "wandb.define_metric(\"number_of_actions_in_episode\", step_metric='episode')\n",
    "\n",
    "def trainIters(policy_net, achieved_rewards,running_sum, counter, win_count, n_iters=60):\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=config.get(\n",
    "        \"lr\"), weight_decay=config.get(\"weight_decay\"))\n",
    "    memory = ReplayMemory(config.get(\"REPLAY_BUFFER\"))\n",
    "    for iteration in range(n_iters):\n",
    "\n",
    "        # wrapped = HumanRendering(env)\n",
    "\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        # wrapped.reset()\n",
    "\n",
    "        # state based on patch of screen (3x3 around agent)\n",
    "        state = get_screen()\n",
    "        spel_gelukt = 0\n",
    "        \n",
    "        for t in count():\n",
    "            env.render()\n",
    "            # wrapped._render_frame()\n",
    "            action = select_action(state)\n",
    "            _, reward, done, _, _ = env.step(action.item())\n",
    "            \n",
    "            running_sum += reward\n",
    "            counter += 1\n",
    "            mean = running_sum / counter\n",
    "\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            \n",
    "            if not done:\n",
    "                next_state = get_screen()\n",
    "\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            optimize_model(policy_net, optimizer, memory)\n",
    "\n",
    "            # if agent did not reach target after RESET_ENV_FREQ actions, reset environment\n",
    "            if (t + 1) % config.get(\"RESET_ENV_FREQ\") == 0:\n",
    "                done = True\n",
    "\n",
    "            if done:\n",
    "                if reward == 2500:\n",
    "                    spel_gelukt = 1\n",
    "                    win_count += 1\n",
    "\n",
    "                log_dict = {\n",
    "                    \"episode\": iteration + 1,\n",
    "                    \"reached_target\": spel_gelukt\n",
    "                }\n",
    "                wandb.log(log_dict)\n",
    "                wandb.log({\"number_of_actions_in_episode\": t})\n",
    "                wandb.log({\"win_count\": win_count})\n",
    "                wandb.log({\"mean_reward\": mean})\n",
    "                break\n",
    "            \n",
    "\n",
    "        # Update the target network, copying all weights and biases to target DQN\n",
    "        if iteration % config.get(\"TARGET_UPDATE\") == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        # save model after frequency\n",
    "        if iteration % config.get(\"SAVE_FREQ\") == 0:\n",
    "            torch.save(policy_net, './model/difference_in_distance_reward' + str(iteration) + '.pkl')\n",
    "        \n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    env.render()\n",
    "    env.close()\n",
    "\n",
    "    # wrapped.render()\n",
    "    # wrapped.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # variables for logging\n",
    "    win_count = 0\n",
    "    achieved_rewards = torch.tensor([], device=device)\n",
    "    running_sum = achieved_rewards.sum()\n",
    "    counter = achieved_rewards.numel()\n",
    "\n",
    "    # Get screen size so that we can initialize layers correctly based on shape\n",
    "    # returned from AI gym. \n",
    "\n",
    "    init_screen = get_screen()\n",
    "    _, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "    # Get number of actions from gym action space\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    # policy_net = torch.load('./model/gridpath_andere_afmeting_kleinere_rb.pkl')\n",
    "    policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    # 20 iteraties\n",
    "    trainIters(policy_net, achieved_rewards, running_sum, counter, win_count, n_iters=config.get('EPISODES'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net, './model/difference_in_distance_reward_end.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b15ee443de15a7c7a9e59449ab0d06bb25873493c1d52931efe00f2e6ab94104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
